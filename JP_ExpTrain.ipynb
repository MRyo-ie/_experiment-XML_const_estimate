{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python384jvsc74a57bd0d89399c061695a917c52cad24deccdb0a4139cdab3cdd06d8ca08ac226240f07",
   "display_name": "Python 3.8.4 64-bit ('3.8.4': pyenv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "2570507ff5ce8377770f843f2fd95b1e7af5e3bf65b540daf9dcf3f3f6ec669e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "\n",
    "from utils.Logger import showPlot\n",
    "from utils.Timer import asMinutes, timeSince\n",
    "\n",
    "%load_ext autoreload\n",
    "from data.exampleJP_Data import Lang, prepareData\n",
    "from model.seq2seq_Model import (\n",
    "    Seq2Seq_LSTM_Attn_ptModel, \n",
    "    Seq2SeqTranslate_ptTokenizer,\n",
    ")\n",
    "from baselineJP_ExpTrain import example_ExpTrain\n",
    "%autoreload"
   ]
  },
  {
   "source": [
    "## load data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mkdir: _data_example/: File exists\n",
      "/Volumes/GoogleDrive/マイドライブ/__datasets__/[CV][NLP]「センター試験xml」/annotate_img/datas/center_exam_2011/construct/Experiment/_data_example\n",
      "fatal: destination path 'small_parallel_enja' already exists and is not an empty directory.\n",
      "------------------\n",
      "i can 't tell who will arrive first .\n",
      "many animals have been destroyed by men .\n",
      "i 'm in the tennis club .\n",
      "emi looks happy .\n",
      "please bear this fact in mind .\n",
      "誰 が 一番 に 着 く か 私 に は 分か り ま せ ん 。\n",
      "多く の 動物 が 人間 に よ っ て 滅ぼ さ れ た 。\n",
      "私 は テニス 部員 で す 。\n",
      "エミ は 幸せ そう に 見え ま す 。\n",
      "この 事実 を 心 に 留め て お い て 下さ い 。\n",
      "------------------\n",
      "\u001b[36mdata\u001b[m\u001b[m                data.zip            \u001b[36msmall_parallel_enja\u001b[m\u001b[m\n",
      "/Volumes/GoogleDrive/マイドライブ/__datasets__/[CV][NLP]「センター試験xml」/annotate_img/datas/center_exam_2011/construct/Experiment\n"
     ]
    }
   ],
   "source": [
    "!mkdir _data_example/\n",
    "%cd '_data_example'\n",
    "\n",
    "if True:    # 解凍する場合は True に書き換え\n",
    "    !git clone https://github.com/odashi/small_parallel_enja\n",
    "    !echo '------------------'\n",
    "    !head -n 5 small_parallel_enja/train.en\n",
    "    !head -n 5 small_parallel_enja/train.ja\n",
    "    !echo '------------------'\n",
    "!ls\n",
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Reading lines...\n",
      "Read 50000 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "en 6637\n",
      "ja 8777\n",
      "['he was also kind to animals .', '彼 は また 動物 たち に 優し かっ た 。']\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, pairs = prepareData('en', 'ja', '_data_example/small_parallel_enja', False)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train / test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_pairs, test_pairs = train_test_split(pairs, test_size=0.2)"
   ]
  },
  {
   "source": [
    "## setup Experiment"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "source": [
    "## setup Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Reading lines...\n",
      "Read 50000 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "ja 8777\n",
      "en 6637\n",
      "['胸焼け が し ま す 。', 'i have heartburn .']\n"
     ]
    }
   ],
   "source": [
    "## Data\n",
    "input_lang, output_lang, pairs = prepareData(\n",
    "        'en', 'ja', '_data_example/small_parallel_enja', True)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "source": [
    "## setup Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'hidden_size' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-970ebf4fbf5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     input_lang, output_lang, device)\n\u001b[1;32m      4\u001b[0m seq2seq_model = Seq2Seq_LSTM_Attn_ptModel(\n\u001b[0;32m----> 5\u001b[0;31m                     \u001b[0minput_lang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_lang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m                     tokenizer, device, dropout_p=0.1)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hidden_size' is not defined"
     ]
    }
   ],
   "source": [
    "## Model\n",
    "tokenizer = Seq2SeqTranslate_ptTokenizer(\n",
    "                    input_lang, output_lang, device)\n",
    "seq2seq_model = Seq2Seq_LSTM_Attn_ptModel(\n",
    "                    input_lang.n_words, output_lang.n_words, hidden_size,\n",
    "                    tokenizer, device, dropout_p=0.1)"
   ]
  },
  {
   "source": [
    "## setup exec"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'seq2seq_model' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-21c5dcf4ea77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mepoch_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m75\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mexp_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexample_ExpTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m exp_train.exec(seq2seq_model, epoch_num, \n\u001b[0m\u001b[1;32m      5\u001b[0m                 \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                 learning_rate=0.01, log_dir='_logs')\n",
      "\u001b[0;31mNameError\u001b[0m: name 'seq2seq_model' is not defined"
     ]
    }
   ],
   "source": [
    "## exec\n",
    "exp_train = example_ExpTrain(pairs)\n",
    "exp_train.exec(seq2seq_model, 50,\n",
    "                print_every=100, plot_every=10, \n",
    "                learning_rate=0.01, log_dir='_logs')\n",
    "# 本実験\n",
    "# exp_train.exec(seq2seq_model, 75000,\n",
    "#                 print_every=5000, plot_every=1000, \n",
    "#                 learning_rate=0.01, log_dir='_logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "___"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## evaluate\n",
    "- random print\n",
    "- Acc\n",
    "- BLEU などの 評価指標"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "from baseline_ExpEval import eval_print_randomly\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "> je suis sure que tom va le faire .\n= i m sure that tom will do that .\n< you re . \n\n> je ne suis pas facilement offensee .\n= i m not easily offended .\n< you re . \n\n> elle est en relation avec cette societe .\n= she is connected with that company .\n< you re . \n\n> elle a presse un citron pour le the .\n= she squeezed a lemon for tea .\n< you re . \n\n> je suis heureux que tu aies mentionne cela .\n= i m glad you brought this up .\n< you re . \n\n> je suis surprise de vous voir .\n= i m surprised to see you .\n< you re . \n\n> il est reporter pour le time .\n= he is a reporter for time magazine .\n< you re . \n\n> tu te fais comprendre .\n= you re assertive .\n< you re . \n\n> ils n ont pas froid aux yeux .\n= they re brave .\n< you re . \n\n> ils sont tous les memes .\n= they are all the same .\n< you re . \n\n"
     ]
    }
   ],
   "source": [
    "eval_print_randomly(seq2seq_model, pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}